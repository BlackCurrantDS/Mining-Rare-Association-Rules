{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnexpctedRules_Evaluation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPI0lYYE7Us22h7q8iAR1+F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlackCurrantDS/DBSE_Project/blob/main/UnexpctedRules_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqZgiZaL49B2"
      },
      "source": [
        "from sklearn.metrics.ranking import roc_curve, auc\r\n",
        "from sklearn.metrics.classification import f1_score\r\n",
        "from sklearn.svm.classes import SVC\r\n",
        "from sklearn.ensemble.forest import RandomForestClassifier"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzkyrBLLFfNs"
      },
      "source": [
        "\r\n",
        "\r\n",
        "class AssociationRule:\r\n",
        "    def __init__(self, left, right):\r\n",
        "        self.left_items = left\r\n",
        "        self.right_items = right\r\n",
        "        self.scores = []\r\n",
        "        \r\n",
        "    def length(self):\r\n",
        "        return len(self.left_items) + len(self.right_items)\r\n",
        "     \r\n",
        "    def score(self, index):\r\n",
        "        return self.scores[index]\r\n",
        "    \r\n",
        "    def lhs_string(self):\r\n",
        "        return itemset_2_string(self.left_items)\r\n",
        "        \r\n",
        "    def rhs_string(self):\r\n",
        "        return itemset_2_string(self.right_items)\r\n",
        "    \r\n",
        "    def serialize(self):\r\n",
        "        left_key = self.lhs_string()\r\n",
        "        right_key = self.rhs_string()\r\n",
        "        return left_key + \">\" + right_key\r\n",
        "    \r\n",
        "    @staticmethod        \r\n",
        "    def string_2_rule(s):\r\n",
        "        subStrings = s.split(\">\")\r\n",
        "        left = string_2_itemset(subStrings[0].strip())\r\n",
        "        right = string_2_itemset(subStrings[1].strip())\r\n",
        "        #print(\"AssociationRule(left, right\",AssociationRule(left, right))\r\n",
        "        return AssociationRule(left, right)\r\n",
        "\r\n",
        "    def append_score(self, score):\r\n",
        "        self.scores.append(score)\r\n",
        "        \r\n",
        "    def get_itemset(self):\r\n",
        "        itemset = []\r\n",
        "        itemset.extend(self.left_items)\r\n",
        "        itemset.extend(self.right_items)\r\n",
        "        itemset.sort()\r\n",
        "        return itemset\r\n",
        "        \r\n",
        "        \r\n",
        "    def rule_itemset_2_string(self):\r\n",
        "        itemset = self.get_itemset()\r\n",
        "        return itemset_2_string(itemset)\r\n",
        "    \r\n",
        "    def compute_basic_probs(self,frequent_itemsets, nTransactions):  \r\n",
        "        \r\n",
        "        left = frequent_itemsets[self.lhs_string()]\r\n",
        "        right = frequent_itemsets[self.rhs_string()]\r\n",
        "        \r\n",
        "        both = frequent_itemsets[self.rule_itemset_2_string()]\r\n",
        "        \r\n",
        "        vector = {}\r\n",
        "        \r\n",
        "        ''' 1. P(A)'''\r\n",
        "        p_A = left/nTransactions\r\n",
        "        vector['A'] = p_A\r\n",
        "        \r\n",
        "        ''' 2. P(B)'''\r\n",
        "        p_B = right/nTransactions\r\n",
        "        vector['B'] = p_B\r\n",
        "        \r\n",
        "        ''' 3. P(~A)'''\r\n",
        "        p_not_A = 1 - p_A\r\n",
        "        vector['~A'] = p_not_A\r\n",
        "        \r\n",
        "        ''' 4. P(~B)'''\r\n",
        "        p_not_B = 1 - p_B\r\n",
        "        vector['~B'] = p_not_B\r\n",
        "        \r\n",
        "        ''' 5. P(AB) '''\r\n",
        "        p_A_and_B = both/nTransactions\r\n",
        "        vector['AB'] = p_A_and_B\r\n",
        "        \r\n",
        "        ''' 6. P(~AB)'''\r\n",
        "        p_not_A_and_B = (right - both)/nTransactions\r\n",
        "        vector['~AB'] = p_not_A_and_B\r\n",
        "        \r\n",
        "        ''' 7. P(A~B)'''\r\n",
        "        p_A_and_not_B = (left - both)/nTransactions\r\n",
        "        vector['A~B'] = p_A_and_not_B\r\n",
        "        \r\n",
        "        ''' 8. P(~A~B)'''\r\n",
        "        p_not_A_and_not_B = 1 - (left + right - both)/nTransactions\r\n",
        "        vector['~A~B'] = p_not_A_and_not_B \r\n",
        "        \r\n",
        "        '''\r\n",
        "        9. P(A|B)\r\n",
        "        '''\r\n",
        "        p_A_if_B = p_A_and_B / p_B\r\n",
        "        vector['A|B'] = p_A_if_B\r\n",
        "        \r\n",
        "        '''\r\n",
        "        10. P(~A|~B)\r\n",
        "        '''\r\n",
        "        p_not_A_if_not_B = p_not_A_and_not_B / p_not_B\r\n",
        "        vector['~A|~B'] = p_not_A_if_not_B\r\n",
        "        \r\n",
        "        '''\r\n",
        "        11. P(A|~B)\r\n",
        "        '''\r\n",
        "        p_A_if_not_B = p_A_and_not_B/p_not_B\r\n",
        "        vector['A|~B'] = p_A_if_not_B\r\n",
        "        \r\n",
        "        '''\r\n",
        "        12. p(~A|B)\r\n",
        "        '''\r\n",
        "        p_not_A_if_B = p_not_A_and_B / p_B\r\n",
        "        vector['~A|B'] = p_not_A_if_B\r\n",
        "        \r\n",
        "        '''\r\n",
        "        13. P(B|A)\r\n",
        "        '''\r\n",
        "        p_B_if_A = p_A_and_B / p_A\r\n",
        "        vector['B|A'] = p_B_if_A\r\n",
        "        \r\n",
        "        '''\r\n",
        "        14. P(~B|~A)\r\n",
        "        '''\r\n",
        "        p_not_B_if_not_A = p_not_A_and_not_B / p_not_A\r\n",
        "        vector['~B|~A'] = p_not_B_if_not_A\r\n",
        "        \r\n",
        "        '''\r\n",
        "        15. P(B|~A)\r\n",
        "        '''\r\n",
        "        p_B_if_not_A = p_not_A_and_B/p_not_A\r\n",
        "        vector['B|~A'] = p_B_if_not_A\r\n",
        "        \r\n",
        "        '''\r\n",
        "        16. p(~B|A)\r\n",
        "        '''\r\n",
        "        p_not_B_if_A = p_A_and_not_B / p_A\r\n",
        "        vector['~B|A'] = p_not_B_if_A\r\n",
        "        \r\n",
        "        return vector\r\n",
        "    \r\n",
        "    def is_redundant_(self, bits, k, itemset, freq_itemset_dict): \r\n",
        "        '''\r\n",
        "        Run out of items --> create rule and check format criterion\r\n",
        "        '''\r\n",
        "        if k >= len(itemset):\r\n",
        "            items_1 = []\r\n",
        "            items_2 = []\r\n",
        "            for index in range(len(bits)):\r\n",
        "                if bits[index] == True:\r\n",
        "                    items_1.append(itemset[index])\r\n",
        "                else:\r\n",
        "                    items_2.append(itemset[index])\r\n",
        "            for item in items_2:\r\n",
        "                rule = AssociationRule(items_1, [item])\r\n",
        "                confidence = freq_itemset_dict.getConfidence(rule)\r\n",
        "                if confidence == 1: return True\r\n",
        "            return False \r\n",
        "      \r\n",
        "        value_domain = [True, False]\r\n",
        "        for value in value_domain:\r\n",
        "            bits[k] = value\r\n",
        "            checker = self.is_redundant_(bits, k+1, itemset, freq_itemset_dict)\r\n",
        "            if checker == True: return True\r\n",
        "            bits[k] = True    \r\n",
        "        return False\r\n",
        "    \r\n",
        "    '''\r\n",
        "    Expand an item-set with equivalent items.\r\n",
        "    '''\r\n",
        "    def is_redundant(self, freq_itemset_dict):\r\n",
        "        bits = [True for _ in self.left_items]\r\n",
        "        checker = self.is_redundant_(bits, 0, self.left_items, freq_itemset_dict)\r\n",
        "        if checker == True: return True\r\n",
        "        \r\n",
        "        bits =  [True for _ in self.right_items]\r\n",
        "        return self.is_redundant_(bits, 0, self.right_items, freq_itemset_dict)\r\n",
        "    \r\n",
        "    '''\r\n",
        "    Check if an item-set is satisfied condition of the rule. \r\n",
        "    '''\r\n",
        "    def satisfy_rule(self, itemset, is_lhs = True):\r\n",
        "        condition = self.left_items\r\n",
        "        if is_lhs == False: condition = self.right_items\r\n",
        "        if len(condition) > len(itemset) or len(itemset) == 0:\r\n",
        "            return False\r\n",
        "        for item in condition:\r\n",
        "            if item not in itemset:\r\n",
        "                return False\r\n",
        "        return True\r\n",
        "    "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbtvr7dmDf6h"
      },
      "source": [
        "'''\r\n",
        "Created on 14 Feb 2018\r\n",
        "\r\n",
        "@author: danhbuithi\r\n",
        "'''\r\n",
        "\r\n",
        "class RelationArray2D(object):\r\n",
        "    '''\r\n",
        "    classdocs\r\n",
        "    '''\r\n",
        "\r\n",
        "    def __init__(self, item_dict, relation_values):\r\n",
        "        '''\r\n",
        "        Constructor\r\n",
        "        '''\r\n",
        "        self.item_dict = item_dict\r\n",
        "        self.relation_matrix = relation_values\r\n",
        "        \r\n",
        "        \r\n",
        "    def get_value(self, item1, item2):\r\n",
        "        i = self.item_dict[item1]\r\n",
        "        j = self.item_dict[item2]\r\n",
        "        return self.relation_matrix[i, j]\r\n",
        "    \r\n",
        "    def get_items(self):\r\n",
        "        return self.item_dict.keys()\r\n",
        "        \r\n",
        "    def get_index(self, item):\r\n",
        "        return self.item_dict[item]\r\n",
        "    \r\n",
        "class RelationArray1D(object):\r\n",
        "    '''\r\n",
        "    classdocs\r\n",
        "    '''\r\n",
        "\r\n",
        "    def __init__(self, item_dict, values):\r\n",
        "        '''\r\n",
        "        Constructor\r\n",
        "        '''\r\n",
        "        self.item_dict = item_dict\r\n",
        "        self.values = values\r\n",
        "        \r\n",
        "        \r\n",
        "    def get_value_at(self, index):\r\n",
        "        return self.values[index]\r\n",
        "    \r\n",
        "    def get_items(self):\r\n",
        "        return self.item_dict.keys()\r\n",
        "        \r\n",
        "    def get_value(self, item):\r\n",
        "        return self.item_dict[item]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRTjXpJE6P01"
      },
      "source": [
        "# Transaction databases, each transaction is a set of items\r\n",
        "import numpy as np\r\n",
        "from scipy import sparse\r\n",
        "from scipy import stats\r\n",
        "\r\n",
        "\r\n",
        "class DataSet:\r\n",
        "    def __init__(self):\r\n",
        "        self.current = 0\r\n",
        "        self.train_data = []\r\n",
        "        self.data_labels = []\r\n",
        "        \r\n",
        "    \r\n",
        "    def __iter__(self):\r\n",
        "        return iter(self.train_data)\r\n",
        "                \r\n",
        "    def size(self):\r\n",
        "        return len(self.train_data)\r\n",
        "    \r\n",
        "    def get_transaction(self, index):\r\n",
        "        return self.train_data[index]\r\n",
        "    \r\n",
        "    def clear(self):\r\n",
        "        self.train_data.clear()\r\n",
        "        \r\n",
        "    def add_transaction(self, t):\r\n",
        "        return self.train_data.append(t) \r\n",
        "        \r\n",
        "    '''\r\n",
        "    Load data set from a file. The input file must be formated in CSV (comma separated)\r\n",
        "    class_index is used in the case of data-set with labels. \r\n",
        "    '''\r\n",
        "    def load(self, file_path, class_index = -1, has_header = False):\r\n",
        "        self.train_data = []\r\n",
        "        if class_index != -1: self.data_labels = []\r\n",
        "        \r\n",
        "        with open(file_path, \"r\") as text_in_file:\r\n",
        "            if has_header == True:\r\n",
        "                text_in_file.readline()\r\n",
        "                \r\n",
        "            for line in text_in_file:\r\n",
        "                #print(\"dataset script line\", line)\r\n",
        "                transaction = [x.strip() for x in line.split(',')]\r\n",
        "                transaction = list(filter(None, transaction))\r\n",
        "                #print(\"datset script transaction\" , transaction)\r\n",
        "                \r\n",
        "                if (class_index != -1):\r\n",
        "                    self.data_labels.append(transaction[class_index])\r\n",
        "                    del transaction[class_index]\r\n",
        "                \r\n",
        "                self.train_data.append(list(set(transaction)))\r\n",
        "        print(\"Loading done\")\r\n",
        "    '''\r\n",
        "    Return number of classes in data (if have).\r\n",
        "    '''            \r\n",
        "    def number_of_classes(self):\r\n",
        "        if self.data_labels == None: return 0\r\n",
        "        return len(set(self.data_labels))\r\n",
        "\r\n",
        "    def convert_data_labels(self, inlier_name):\r\n",
        "        Y_train = np.zeros(len(self.data_labels))\r\n",
        "        for i in range(Y_train.shape[0]):\r\n",
        "            if self.data_labels[i] == inlier_name:\r\n",
        "                Y_train[i] = 1\r\n",
        "            else: \r\n",
        "                Y_train[i] = -1\r\n",
        "        return Y_train\r\n",
        "\r\n",
        "    def convert_2_binary_format_with(self, items_dict, classes_dict = None):\r\n",
        "        n_items = len(items_dict)\r\n",
        "        X_train = np.zeros((self.size(), n_items))\r\n",
        "        \r\n",
        "        k = 0\r\n",
        "        for transaction in self.train_data:\r\n",
        "            for item in transaction:\r\n",
        "                if item not in items_dict: \r\n",
        "                    print('not in features...')\r\n",
        "                    continue\r\n",
        "                i = items_dict[item]\r\n",
        "                X_train[k, i] = 1.0\r\n",
        "            k += 1\r\n",
        "            \r\n",
        "        Y_train = []\r\n",
        "        if classes_dict is not None:\r\n",
        "            for label in self.data_labels:\r\n",
        "                if label not in classes_dict:\r\n",
        "                    print('not in classes')\r\n",
        "                    Y_train.append(-1)\r\n",
        "                else:\r\n",
        "                    Y_train.append(classes_dict[label]) \r\n",
        "        return X_train, np.array(Y_train)        \r\n",
        "    \r\n",
        "    def get_items_dict_(self):\r\n",
        "        attr_dict = {}\r\n",
        "        #check existing data\r\n",
        "        for transaction in self.train_data:\r\n",
        "            for index in range (len(transaction)):\r\n",
        "                item_name = transaction[index]\r\n",
        "                if item_name not in attr_dict:\r\n",
        "                    attr_dict[item_name] = True\r\n",
        "        return attr_dict\r\n",
        "    \r\n",
        "    def get_class_list_(self):\r\n",
        "        # Sort items and classes in alphabet order.\r\n",
        "        return sorted(set(self.data_labels))\r\n",
        "        \r\n",
        "        \r\n",
        "\r\n",
        "    '''\r\n",
        "    Convert transaction data into binary format\r\n",
        "    '''\r\n",
        "    def convert_2_binary_format(self):\r\n",
        "        \r\n",
        "        attr_dict = self.get_items_dict_()\r\n",
        "        print(\"convert_2_binary_format attr_dict\", attr_dict)\r\n",
        "        \"\"\"\r\n",
        "        {'a6@3': True, 'a7@left': True, 'a9@no': True, 'a3@30-34': True, 'a1@30-39': True, 'class@no': True, 'a5@no': True, 'a4@0-2': True, 'a2@premeno': True, 'a8@left_low': True, 'a8@right_up': True, 'a3@20-24': True, 'a7@right': True, 'a1@40-49': True, 'a6@2': True, 'a8@left_up': True, 'a2@ge40': True, 'a1@60-69': True, 'a3@15-19': True, 'a8@right_low': True, 'a3@0-4': True, 'a3@25-29': True, 'a1@50-59': True, 'a3@50-54': True, 'a8@central': True, 'a6@1': True, 'a3@10-14': True, 'a2@lt40': True, 'a3@40-44': True, 'a3@35-39': True, 'a1@70-79': True, 'a3@5-9': True, 'a9@yes': True, 'a5@yes': True, 'a4@6-8': True, 'a4@9-11': True, 'a4@3-5': True, 'a3@45-49': True, 'a5@?': True, 'a4@15-17': True, 'a4@12-14': True, 'class@yes': True, 'a8@?': True, 'a4@24-26': True}\r\n",
        "        \r\n",
        "        \r\n",
        "        \"\"\"\r\n",
        "         \r\n",
        "        # Sort items and classes in alphabet order.\r\n",
        "        classes_list = sorted(set(self.data_labels))\r\n",
        "        items_list = sorted(attr_dict.keys())\r\n",
        "        \r\n",
        "        classes_dict = {classes_list[i] : i for i in range(len(classes_list))}\r\n",
        "        attr_dict = {items_list[i] : i for i in range(len(items_list))}\r\n",
        "        \r\n",
        "        #Generate binary matrix (X_train) and array of labels(Y_train)\r\n",
        "        X_train, Y_train = self.convert_2_binary_format_with(attr_dict, classes_dict)\r\n",
        "                \r\n",
        "        return RelationArray2D(attr_dict, sparse.csr_matrix(X_train)), RelationArray1D(classes_dict, np.array(Y_train))\r\n",
        "        \r\n",
        "    @staticmethod\r\n",
        "    def write_relation_matrix_(matrix):\r\n",
        "        with open('item_relation.csv', 'w') as file_writer:\r\n",
        "            item_names = sorted(matrix.item_dict.keys())\r\n",
        "            file_writer.write('o0o,')\r\n",
        "            file_writer.write(','.join(item_names))\r\n",
        "            file_writer.write('\\n')\r\n",
        "            for i in range(len(item_names)):\r\n",
        "                file_writer.write(item_names[i] + ',')\r\n",
        "                file_writer.write(','.join(str(x) for x in matrix.relation_matrix[i].tolist()))\r\n",
        "                file_writer.write('\\n')\r\n",
        "                \r\n",
        "                \r\n",
        "   \r\n",
        "    '''\r\n",
        "    This method estimates relationship among items. There're two kinds of relationship\r\n",
        "    - Correlation:including negative correlation (<= -0.3) and positive correlation (>= 0.3)\r\n",
        "    - Cover: threshold 1.0, including cover (2) and covered (-2) \r\n",
        "    '''\r\n",
        "    def items_relationship(self):\r\n",
        "        \r\n",
        "        print ('Computing item relation matrix...')\r\n",
        "        \r\n",
        "        X_train, _ = self.convert_2_binary_format()\r\n",
        "        \r\n",
        "        print(\"X_train\",X_train)\r\n",
        "    \r\n",
        "        correlation_matrix, p_values = stats.spearmanr(X_train.relation_matrix.todense(), axis = 0)\r\n",
        "        \r\n",
        "        zeros_mask = (p_values <= 0.05).astype(int)\r\n",
        "        small_mask = (np.abs(correlation_matrix) >= 0.1).astype(int)\r\n",
        "        \r\n",
        "        relation_matrix = correlation_matrix * small_mask * zeros_mask\r\n",
        "        \r\n",
        "        a = RelationArray2D(X_train.item_dict, relation_matrix)\r\n",
        "        DataSet.write_relation_matrix_(a)\r\n",
        "        \r\n",
        "        return a"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQzXb6vnDL76"
      },
      "source": [
        "train_data_set = DataSet()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiJEAVwYDo4a",
        "outputId": "ac47b470-a917-4818-b5da-198066acccd8"
      },
      "source": [
        "train_data_set.load(\"/content/breast_train_transactions.txt\", 0, has_header = False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIdEQT-EDUd5",
        "outputId": "e2cbfc1a-a454-4818-cc55-ad85e6dc6a8f"
      },
      "source": [
        "X_train, Y_train = train_data_set.convert_2_binary_format()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert_2_binary_format attr_dict {'a4@0-2': True, 'a6@3': True, 'a3@30-34': True, 'a1@30-39': True, 'a7@left': True, 'a8@left_low': True, 'a5@no': True, 'a9@no': True, 'a2@premeno': True, 'a6@2': True, 'a8@right_up': True, 'a1@40-49': True, 'a7@right': True, 'a3@20-24': True, 'a3@15-19': True, 'a8@left_up': True, 'a1@60-69': True, 'a2@ge40': True, 'a8@right_low': True, 'a3@0-4': True, 'a1@50-59': True, 'a3@25-29': True, 'a3@50-54': True, 'a8@central': True, 'a2@lt40': True, 'a6@1': True, 'a3@10-14': True, 'a3@40-44': True, 'a3@35-39': True, 'a1@70-79': True, 'a3@5-9': True, 'a5@yes': True, 'a9@yes': True, 'a4@6-8': True, 'a4@9-11': True, 'a4@3-5': True, 'a3@45-49': True, 'a5@?': True, 'a4@15-17': True, 'a4@12-14': True, 'a8@?': True, 'a4@24-26': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7n9R_JXDy24",
        "outputId": "a031461e-f8fc-4340-b912-ba21cb26d103"
      },
      "source": [
        "test_data_set = DataSet()\r\n",
        "test_data_set.load(\"/content/breast_test_transactions.txt\", 0, has_header = False)\r\n",
        "Xtest, Ytest = test_data_set.convert_2_binary_format_with(X_train.item_dict, Y_train.item_dict)\r\n",
        "Ytest = Ytest.flatten()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading done\n",
            "not in features...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEPvCOaNEC_b"
      },
      "source": [
        "class_count = train_data_set.number_of_classes()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN-eQoEiHKd5"
      },
      "source": [
        "import json\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class IOHelper:\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def write_file_in_lines(file_name, data, header = None):\r\n",
        "        with open(file_name, \"w\") as text_file:\r\n",
        "            if header is not None:\r\n",
        "                text_file.write(header)\r\n",
        "                text_file.write('\\n')\r\n",
        "            for transaction in data:\r\n",
        "                text_file.write(transaction)\r\n",
        "                text_file.write('\\n')\r\n",
        "    \r\n",
        "    @staticmethod        \r\n",
        "    def read_file_in_lines(inputfile, has_header = False):\r\n",
        "        data = []\r\n",
        "        with open(inputfile, \"r\") as text_file:\r\n",
        "            file_iter = iter(text_file)\r\n",
        "            if has_header == True:\r\n",
        "                next(file_iter)\r\n",
        "            \r\n",
        "            for line in file_iter:\r\n",
        "                data.append(line.strip())\r\n",
        "        return data\r\n",
        "    \r\n",
        "    @staticmethod\r\n",
        "    def read_ranking_file(input_file):\r\n",
        "        patterns = []\r\n",
        "        ranking = []\r\n",
        "        k = 0\r\n",
        "        with open(input_file, \"r\") as text_file:\r\n",
        "            for line in text_file:\r\n",
        "                subStrings = line.split(';')\r\n",
        "                rule_key = subStrings[0].strip()\r\n",
        "                patterns.append(rule_key)\r\n",
        "                ranking.append([])\r\n",
        "                for v in subStrings[1:]:\r\n",
        "                    r = int(v)\r\n",
        "                    ranking[k].append(r)\r\n",
        "                \r\n",
        "                k += 1\r\n",
        "                if k % 1000 == 0: print(str(k))\r\n",
        "        return patterns, np.array(ranking)\r\n",
        "    \r\n",
        "    @staticmethod \r\n",
        "    def save_as_json_format(file_name, o):\r\n",
        "        with open (file_name, 'w') as text_file:\r\n",
        "            json.dump(o, text_file)\r\n",
        "            \r\n",
        "    @staticmethod \r\n",
        "    def save_as_json_format_in_line(file_name, o):\r\n",
        "        with open (file_name, 'w') as text_file:\r\n",
        "            #json.dump(o, text_file)\r\n",
        "            for item in o:\r\n",
        "                line = json.dumps(item)\r\n",
        "                text_file.write(line)\r\n",
        "                text_file.write('\\n')\r\n",
        "            \r\n",
        "    @staticmethod        \r\n",
        "    def load_json_object(file_name):\r\n",
        "        with open(file_name, 'r') as text_file:\r\n",
        "            o = json.load(text_file)\r\n",
        "            return o\r\n",
        "    \r\n",
        "    @staticmethod    \r\n",
        "    def write_matrix(file_name, matrix):\r\n",
        "        with open(file_name, \"w\") as text_file:\r\n",
        "            for line in matrix:\r\n",
        "                text_file.write(','.join(str(x) for x in line.tolist()))\r\n",
        "                text_file.write('\\n')\r\n",
        "    \r\n",
        "    @staticmethod\r\n",
        "    def write_list_of_tuples(file_name, tuples_list):\r\n",
        "        with open(file_name, 'w') as writer:\r\n",
        "            for rule in tuples_list:\r\n",
        "                writer.write(str(rule))\r\n",
        "                writer.write('\\n')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1v3mHEjE1Gy"
      },
      "source": [
        "unexpected_rules = IOHelper.load_json_object(\"/content/unexpected_rule_file_json\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx43_UvKFpZC",
        "outputId": "fb981097-fc53-4e39-85e1-648d91952492"
      },
      "source": [
        "unexpected_rules"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a2@ge40,a4@3-5,a5@no,a9@no>class@yes',\n",
              "  1.0,\n",
              "  [['a2@ge40,a5@no,a9@no>class@no',\n",
              "    0.8788212007857173,\n",
              "    1.0,\n",
              "    0.8235294117647058]]],\n",
              " ['a5@?,a6@1,a7@left>class@yes',\n",
              "  1.0,\n",
              "  [['a6@1,a7@left>class@no', 0.8416796149986245, 1.0, 0.8]]],\n",
              " ['a1@50-59,a2@ge40,a3@30-34,a6@3,a7@left,a9@no>class@yes',\n",
              "  1.0,\n",
              "  [['a1@50-59,a2@ge40,a7@left,a9@no>class@no', 0.8373564003526225, 1.0, 0.8],\n",
              "   ['a2@ge40,a7@left,a9@no>class@no',\n",
              "    0.8063165178857924,\n",
              "    1.0,\n",
              "    0.8571428571428571]]],\n",
              " ['a2@ge40,a4@3-5,a5@no>class@yes',\n",
              "  1.0,\n",
              "  [['a2@ge40,a5@no,a9@no>class@no',\n",
              "    0.7989617927178548,\n",
              "    0.6666666666666666,\n",
              "    0.8235294117647058],\n",
              "   ['a2@ge40,a5@no,a7@left>class@no',\n",
              "    0.7195768942672236,\n",
              "    0.5,\n",
              "    0.8333333333333334]]],\n",
              " ['a2@ge40,a4@3-5,a5@no,a8@left_low>class@yes',\n",
              "  1.0,\n",
              "  [['a2@ge40,a5@no,a7@left>class@no',\n",
              "    0.7685496069569597,\n",
              "    0.75,\n",
              "    0.8333333333333334]]],\n",
              " ['a1@30-39,a2@premeno,a4@0-2,a8@left_up>class@yes',\n",
              "  0.8,\n",
              "  [['a4@0-2,a5@no,a8@left_up>class@no', 0.7481485499239875, 1.0, 0.8],\n",
              "   ['a4@0-2,a5@no,a8@left_up,a9@no>class@no',\n",
              "    0.7097521128740405,\n",
              "    0.8,\n",
              "    0.8043478260869565],\n",
              "   ['a4@0-2,a5@no,a7@left,a9@no>class@no', 0.38874554033172815, 0.6, 0.825]]],\n",
              " ['a1@30-39,a2@premeno,a5@no,a8@left_up>class@yes',\n",
              "  0.8571428571428571,\n",
              "  [['a4@0-2,a5@no,a8@left_up>class@no',\n",
              "    0.7404497704761877,\n",
              "    0.7142857142857143,\n",
              "    0.8],\n",
              "   ['a4@0-2,a5@no,a8@left_up,a9@no>class@no',\n",
              "    0.6958410675657126,\n",
              "    0.5714285714285714,\n",
              "    0.8043478260869565],\n",
              "   ['a2@premeno,a6@2,a8@left_up>class@no',\n",
              "    0.6502481714542082,\n",
              "    0.42857142857142855,\n",
              "    0.8095238095238095]]],\n",
              " ['a6@3,a7@right,a8@right_up,a9@no>class@yes',\n",
              "  0.8,\n",
              "  [['a4@0-2,a7@right,a8@right_up,a9@no>class@no',\n",
              "    0.7344051752119988,\n",
              "    0.6,\n",
              "    0.8333333333333334]]],\n",
              " ['a2@ge40,a4@3-5,a6@3,a8@left_low>class@yes',\n",
              "  0.8,\n",
              "  [['a2@ge40,a3@30-34,a8@left_low>class@no', 0.7308972731553077, 0.6, 0.8],\n",
              "   ['a2@ge40,a7@left,a8@left_low,a9@no>class@no',\n",
              "    0.3987437890156873,\n",
              "    0.6,\n",
              "    0.8333333333333334],\n",
              "   ['a2@ge40,a7@left,a9@no>class@no',\n",
              "    0.293354709873896,\n",
              "    0.6,\n",
              "    0.8571428571428571]]],\n",
              " ['a2@ge40,a3@30-34,a4@3-5,a5@no>class@yes',\n",
              "  1.0,\n",
              "  [['a2@ge40,a5@no,a9@no>class@no',\n",
              "    0.7301799138143252,\n",
              "    1.0,\n",
              "    0.8235294117647058]]],\n",
              " ['a3@25-29,a5@no,a6@3,a7@left>class@yes',\n",
              "  0.8,\n",
              "  [['a4@0-2,a5@no,a7@left>class@no',\n",
              "    0.7267820826338393,\n",
              "    0.8,\n",
              "    0.8043478260869565],\n",
              "   ['a5@no,a7@left,a9@no>class@no',\n",
              "    0.7023555685360396,\n",
              "    0.6,\n",
              "    0.8072289156626506],\n",
              "   ['a4@0-2,a5@no,a7@left,a9@no>class@no', 0.6958893499626995, 0.6, 0.825]]],\n",
              " ['a1@50-59,a3@30-34,a6@3,a7@left,a9@no>class@yes',\n",
              "  0.8,\n",
              "  [['a3@30-34,a4@0-2,a7@left,a9@no>class@no',\n",
              "    0.7168126673995391,\n",
              "    0.6,\n",
              "    0.8235294117647058],\n",
              "   ['a1@50-59,a2@ge40,a7@left,a9@no>class@no', 0.7070428552789277, 0.6, 0.8],\n",
              "   ['a2@ge40,a7@left,a9@no>class@no',\n",
              "    0.6593348537248928,\n",
              "    0.6,\n",
              "    0.8571428571428571]]],\n",
              " ['a1@60-69,a6@3,a7@right,a9@no>class@yes',\n",
              "  0.8,\n",
              "  [['a2@ge40,a4@0-2,a7@right,a9@no>class@no',\n",
              "    0.7130925262468668,\n",
              "    0.8,\n",
              "    0.8064516129032258],\n",
              "   ['a2@ge40,a4@0-2,a5@no,a7@right,a9@no>class@no',\n",
              "    0.7006184722221338,\n",
              "    0.8,\n",
              "    0.8],\n",
              "   ['a1@60-69,a2@ge40,a5@no,a9@no>class@no',\n",
              "    0.6103665629796643,\n",
              "    0.8,\n",
              "    0.8214285714285714]]],\n",
              " ['a1@50-59,a2@ge40,a3@30-34,a6@3,a9@no>class@yes',\n",
              "  0.8,\n",
              "  [['a1@50-59,a2@ge40,a5@no,a9@no>class@no',\n",
              "    0.7130235164107288,\n",
              "    0.8,\n",
              "    0.8529411764705882],\n",
              "   ['a1@50-59,a2@ge40,a7@left,a9@no>class@no', 0.6819060779245765, 0.6, 0.8],\n",
              "   ['a2@ge40,a5@no,a9@no>class@no',\n",
              "    0.6649086661073329,\n",
              "    0.8,\n",
              "    0.8235294117647058]]],\n",
              " ['a2@ge40,a4@3-5,a6@3,a7@right>class@yes',\n",
              "  0.8,\n",
              "  [['a1@50-59,a2@ge40,a7@right>class@no',\n",
              "    0.7039813304630965,\n",
              "    0.6,\n",
              "    0.8636363636363636]]],\n",
              " ['a2@ge40,a3@30-34,a4@3-5>class@yes',\n",
              "  0.8,\n",
              "  [['a2@ge40,a3@30-34,a8@left_low>class@no', 0.7002924935477179, 0.6, 0.8],\n",
              "   ['a2@ge40,a7@left,a9@no>class@no',\n",
              "    0.20600767772867257,\n",
              "    0.6,\n",
              "    0.8571428571428571],\n",
              "   ['a2@ge40,a7@left,a8@left_low,a9@no>class@no',\n",
              "    0.1890528402532266,\n",
              "    0.6,\n",
              "    0.8333333333333334]]],\n",
              " ['a4@3-5,a5@no,a7@left>class@yes',\n",
              "  1.0,\n",
              "  [['a2@ge40,a5@no,a7@left>class@no',\n",
              "    0.6892067807003556,\n",
              "    1.0,\n",
              "    0.8333333333333334]]],\n",
              " ['a2@ge40,a4@3-5,a5@no,a6@3>class@yes',\n",
              "  1.0,\n",
              "  [['a2@ge40,a5@no,a9@no>class@no',\n",
              "    0.6614363881218057,\n",
              "    0.75,\n",
              "    0.8235294117647058]]],\n",
              " ['a3@30-34,a4@3-5,a5@no,a9@no>class@yes',\n",
              "  1.0,\n",
              "  [['a2@ge40,a5@no,a9@no>class@no',\n",
              "    0.6049688935272056,\n",
              "    0.75,\n",
              "    0.8235294117647058]]],\n",
              " ['a1@40-49,a6@3,a7@right,a9@no>class@yes',\n",
              "  0.8,\n",
              "  [['a4@0-2,a7@right,a8@right_up,a9@no>class@no',\n",
              "    0.580483996721926,\n",
              "    0.6,\n",
              "    0.8333333333333334]]],\n",
              " ['a2@ge40,a5@no,a6@3,a9@yes>class@yes',\n",
              "  0.8,\n",
              "  [['a2@ge40,a4@0-2,a5@no>class@no',\n",
              "    0.5548782326222182,\n",
              "    0.6,\n",
              "    0.8472222222222222],\n",
              "   ['a2@ge40,a4@0-2>class@no', 0.5193894354578119, 0.6, 0.8513513513513513],\n",
              "   ['a1@60-69,a2@ge40,a4@0-2>class@no', 0.49977569751985657, 0.6, 0.8]]],\n",
              " ['a2@premeno,a4@0-2,a6@3,a8@right_up>class@yes',\n",
              "  0.8,\n",
              "  [['a4@0-2,a7@right,a8@right_up,a9@no>class@no',\n",
              "    0.5542525000995197,\n",
              "    0.6,\n",
              "    0.8333333333333334]]],\n",
              " ['a2@premeno,a6@3,a7@right,a9@no>class@yes',\n",
              "  0.8333333333333334,\n",
              "  [['a4@0-2,a7@right,a8@right_up,a9@no>class@no',\n",
              "    0.5531062564938579,\n",
              "    0.5,\n",
              "    0.8333333333333334]]],\n",
              " ['a1@60-69,a7@left,a8@left_low>class@no',\n",
              "  0.8,\n",
              "  [['a5@yes,a6@3,a7@left,a8@left_low>class@yes',\n",
              "    0.5483352367356918,\n",
              "    0.375,\n",
              "    0.875],\n",
              "   ['a5@yes,a6@3,a7@left>class@yes',\n",
              "    0.4226383085830375,\n",
              "    0.23076923076923078,\n",
              "    0.8461538461538461],\n",
              "   ['a5@yes,a6@3,a8@left_low>class@yes', 0.3688560278043778, 0.3, 0.8]]],\n",
              " ['a4@3-5,a5@no,a8@left_low>class@yes',\n",
              "  0.8,\n",
              "  [['a2@ge40,a5@no,a7@left>class@no',\n",
              "    0.5398543095428714,\n",
              "    0.6,\n",
              "    0.8333333333333334]]],\n",
              " ['a2@premeno,a6@3,a8@right_up,a9@no>class@yes',\n",
              "  0.8333333333333334,\n",
              "  [['a4@0-2,a7@right,a8@right_up,a9@no>class@no',\n",
              "    0.500302774343299,\n",
              "    0.5,\n",
              "    0.8333333333333334]]],\n",
              " ['a3@30-34,a4@3-5,a5@no>class@yes',\n",
              "  1.0,\n",
              "  [['a2@ge40,a5@no,a9@no>class@no',\n",
              "    0.4796118112839125,\n",
              "    0.6,\n",
              "    0.8235294117647058]]],\n",
              " ['a2@ge40,a9@no>class@no',\n",
              "  0.8024691358024691,\n",
              "  [['a4@3-5,a5@no,a6@3,a9@no>class@yes', 0.42230623860111904, 1.0, 1.0],\n",
              "   ['a4@3-5,a5@no,a6@3>class@yes',\n",
              "    0.21903402655587578,\n",
              "    0.5,\n",
              "    0.8333333333333334],\n",
              "   ['a3@30-34,a4@3-5,a5@no,a6@3>class@yes', 0.20018459488751494, 0.75, 1.0]]],\n",
              " ['a1@30-39,a3@30-34,a8@left_up>class@yes',\n",
              "  0.8,\n",
              "  [['a2@premeno,a6@2,a8@left_up>class@no',\n",
              "    0.4145560477814059,\n",
              "    0.6,\n",
              "    0.8095238095238095],\n",
              "   ['a4@0-2,a5@no,a8@left_up>class@no', 0.22910305132289635, 0.6, 0.8],\n",
              "   ['a4@0-2,a5@no,a8@left_up,a9@no>class@no',\n",
              "    0.1931864981663849,\n",
              "    0.6,\n",
              "    0.8043478260869565]]],\n",
              " ['a1@50-59,a4@3-5,a6@3>class@yes',\n",
              "  0.8,\n",
              "  [['a1@50-59,a2@ge40,a7@right>class@no',\n",
              "    0.2916695612671162,\n",
              "    0.6,\n",
              "    0.8636363636363636]]],\n",
              " ['a2@premeno,a7@left,a8@right_up>class@yes',\n",
              "  0.8,\n",
              "  [['a4@0-2,a5@no,a7@left>class@no',\n",
              "    0.28476850296003203,\n",
              "    0.8,\n",
              "    0.8043478260869565],\n",
              "   ['a5@no,a7@left,a9@no>class@no',\n",
              "    0.26206955483527244,\n",
              "    0.8,\n",
              "    0.8072289156626506],\n",
              "   ['a4@0-2,a7@left,a9@no>class@no',\n",
              "    0.2589772281354866,\n",
              "    0.8,\n",
              "    0.8072289156626506]]],\n",
              " ['a2@ge40,a4@6-8,a6@3>class@yes',\n",
              "  0.8,\n",
              "  [['a2@ge40,a7@left,a9@no>class@no',\n",
              "    0.25823734850953656,\n",
              "    0.6,\n",
              "    0.8571428571428571]]],\n",
              " ['a1@30-39,a6@3,a8@left_low>class@yes',\n",
              "  0.8,\n",
              "  [['a4@0-2,a7@left,a8@left_low>class@no',\n",
              "    0.1328979383752282,\n",
              "    0.6,\n",
              "    0.8085106382978723],\n",
              "   ['a4@0-2,a5@no,a7@left,a8@left_low>class@no',\n",
              "    0.10303278205730021,\n",
              "    0.6,\n",
              "    0.8260869565217391]]],\n",
              " ['a3@25-29,a6@3,a7@left>class@yes',\n",
              "  0.875,\n",
              "  [['a2@ge40,a5@no,a7@left>class@no',\n",
              "    0.13172926449662656,\n",
              "    0.375,\n",
              "    0.8333333333333334],\n",
              "   ['a4@0-2,a5@no,a7@left>class@no',\n",
              "    0.12825762224176457,\n",
              "    0.5,\n",
              "    0.8043478260869565],\n",
              "   ['a5@no,a7@left,a9@no>class@no',\n",
              "    0.11303920764597687,\n",
              "    0.375,\n",
              "    0.8072289156626506]]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY7PJZyxFVrK"
      },
      "source": [
        "def filter_association_rules(unexpected_rules, delta_1 = 0):\r\n",
        "    rules = []\r\n",
        "    for x in unexpected_rules:\r\n",
        "        if x[2][0][1] > delta_1: \r\n",
        "            rules.append(AssociationRule.string_2_rule(x[0]))\r\n",
        "    return rules"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUKjZ3PQIs-X"
      },
      "source": [
        "def string_2_itemset(key):\r\n",
        "    if key == '':\r\n",
        "        return []\r\n",
        "    else: \r\n",
        "        return key.split(',')\r\n",
        "\r\n",
        "def itemset_2_string(itemset):\r\n",
        "    return \",\".join(itemset)\r\n",
        "\r\n",
        "def merge_itemsets(itemset_1, itemset_2):\r\n",
        "    merged_items = []\r\n",
        "    merged_items.extend(itemset_1)\r\n",
        "    merged_items.extend(itemset_2)\r\n",
        "    merged_items = list(set(merged_items))\r\n",
        "    merged_items = sorted(merged_items)\r\n",
        "    \r\n",
        "    return merged_items\r\n",
        "\r\n",
        "def get_full_path(prefix, file_name):\r\n",
        "    if prefix == '': return file_name\r\n",
        "    return prefix + '//' + file_name\r\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ztudi2TEHQZ"
      },
      "source": [
        "refined_unexpected_rules = filter_association_rules(unexpected_rules)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyJDde0kI0Xm",
        "outputId": "8d35634c-75fc-4617-b95c-3d498d7700e9"
      },
      "source": [
        "print('svm testing...')\r\n",
        "svc_model = SVC(kernel = 'poly', degree=3, coef0 = 0.1, random_state = 1)\r\n",
        "svc_model.fit(X_train.relation_matrix, Y_train.values.flatten())"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "svm testing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.1,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
              "    max_iter=-1, probability=False, random_state=1, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb8u3UFwJSJH"
      },
      "source": [
        "def refine_with_unexpectedness(data_set, classes_dict, preY, Ytrue, unexpected_rules):\r\n",
        "    \r\n",
        "    print('Refine with unexpected rules...')\r\n",
        "    y_pred = np.copy(preY)\r\n",
        "    for i in range(data_set.size()):\r\n",
        "        x = data_set.get_transaction(i)\r\n",
        "        for r in unexpected_rules:\r\n",
        "            if r.satisfy_rule(x, is_lhs = True):\r\n",
        "                label = r.right_items[0]\r\n",
        "                y_pred[i] = classes_dict[label]\r\n",
        "    print(f1_score(Ytrue, y_pred, average=None))\r\n",
        "    if (data_set.number_of_classes() <= 2):\r\n",
        "        fpr, tpr, _ = roc_curve(Ytrue, y_pred.flatten())\r\n",
        "        print(auc(fpr, tpr))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JenXJwU1JFIW"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3QnrJyGI-22",
        "outputId": "37343a33-65ae-4ff1-d570-27c3c1479c3c"
      },
      "source": [
        "svc_y_pred = svc_model.predict(Xtest)\r\n",
        "print(f1_score(Ytest, svc_y_pred, average=None))\r\n",
        "if (class_count <= 2):\r\n",
        "  fpr, tpr, _ = roc_curve(Ytest, svc_y_pred.flatten())    \r\n",
        "  print(auc(fpr, tpr))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.91428571 0.72727273]\n",
            "0.7857142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n98RxYOvJLK3",
        "outputId": "1e42af7e-d266-486d-92fe-b130fd0b54bf"
      },
      "source": [
        "refine_with_unexpectedness(test_data_set, Y_train.item_dict, svc_y_pred, Ytest, refined_unexpected_rules)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Refine with unexpected rules...\n",
            "[0.91176471 0.75      ]\n",
            "0.8058035714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJlBLIOhJGOf"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UukCWLYsJIJ-",
        "outputId": "ff8e2010-2d78-4386-bff4-b0331a46c6d8"
      },
      "source": [
        "print('Random forest testing...')\r\n",
        "rf_model = RandomForestClassifier(n_estimators=20, random_state=1)\r\n",
        "rf_model.fit(X_train.relation_matrix, Y_train.values.flatten())\r\n",
        "    \r\n",
        "rf_y_pred = rf_model.predict(Xtest)\r\n",
        "print(f1_score(Ytest, rf_y_pred, average=None))\r\n",
        "if (class_count <= 2):\r\n",
        "  fpr, tpr, _ = roc_curve(Ytest, rf_y_pred.flatten())\r\n",
        "  print(auc(fpr, tpr))\r\n",
        "    \r\n",
        "refine_with_unexpectedness(test_data_set, Y_train.item_dict, rf_y_pred, Ytest, refined_unexpected_rules)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random forest testing...\n",
            "[0.88571429 0.63636364]\n",
            "0.734375\n",
            "Refine with unexpected rules...\n",
            "[0.89552239 0.72      ]\n",
            "0.7901785714285714\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}