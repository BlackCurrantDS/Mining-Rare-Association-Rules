{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FP_Processing_each_file_clev_with_superset_v1.ipynb",
      "provenance": [],
      "mount_file_id": "1xK3bk6OsyBlZInL6EgOYA1ALo9Ar_dWY",
      "authorship_tag": "ABX9TyNHoRLEK7LoJJYz8DuU+NtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlackCurrantDS/Mining-Rare-Association-Rules/blob/master/FP_Processing_each_file_clev_with_superset_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIHaRw5eHFdO"
      },
      "source": [
        "Generating rule for each file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EexubHst1mvu"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import fileinput"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrssKvI-1XYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016e7cde-4d2f-48a2-aba4-55bae7d4d8dc"
      },
      "source": [
        "#for dictionary\n",
        "originalfile = \"/content/clev_data_original.csv\"\n",
        "\n",
        "df = pd.read_csv(originalfile)\n",
        "\n",
        "#removing index column\n",
        "cols = [0]\n",
        "df.drop(df.columns[cols],axis=1,inplace=True)\n",
        "\n",
        "cols = list(df.columns)\n",
        "cols = [cols[-1]] + cols[:-1]\n",
        "df = df[cols]\n",
        "\n",
        "for i,n in enumerate(df.columns):\n",
        "      if n=='class':\n",
        "        df[n] = 'class@' + df[n].astype(str)\n",
        "      else:\n",
        "        df[n] = 'A'+str(i)+'@' + df[n].astype(str)\n",
        "\n",
        "df['class'] = df['class'].str.replace('2', '1').str.replace('3', '1').str.replace('4', '1')\n",
        "uni = pd.DataFrame()\n",
        "\n",
        "for col in df:\n",
        "  uni= pd.concat([uni, pd.DataFrame(df[col].unique())], ignore_index=True)\n",
        "\n",
        "my_dict = uni.to_dict()\n",
        "\n",
        "my_dict = my_dict[0]\n",
        "\n",
        "my_dict\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'class@0',\n",
              " 1: 'class@1',\n",
              " 2: 'A1@63.0',\n",
              " 3: 'A1@67.0',\n",
              " 4: 'A1@37.0',\n",
              " 5: 'A1@41.0',\n",
              " 6: 'A1@56.0',\n",
              " 7: 'A1@62.0',\n",
              " 8: 'A1@57.0',\n",
              " 9: 'A1@53.0',\n",
              " 10: 'A1@44.0',\n",
              " 11: 'A1@52.0',\n",
              " 12: 'A1@48.0',\n",
              " 13: 'A1@54.0',\n",
              " 14: 'A1@49.0',\n",
              " 15: 'A1@64.0',\n",
              " 16: 'A1@58.0',\n",
              " 17: 'A1@60.0',\n",
              " 18: 'A1@50.0',\n",
              " 19: 'A1@66.0',\n",
              " 20: 'A1@43.0',\n",
              " 21: 'A1@40.0',\n",
              " 22: 'A1@69.0',\n",
              " 23: 'A1@59.0',\n",
              " 24: 'A1@42.0',\n",
              " 25: 'A1@55.0',\n",
              " 26: 'A1@61.0',\n",
              " 27: 'A1@65.0',\n",
              " 28: 'A1@71.0',\n",
              " 29: 'A1@51.0',\n",
              " 30: 'A1@46.0',\n",
              " 31: 'A1@45.0',\n",
              " 32: 'A1@39.0',\n",
              " 33: 'A1@68.0',\n",
              " 34: 'A1@47.0',\n",
              " 35: 'A1@34.0',\n",
              " 36: 'A1@35.0',\n",
              " 37: 'A1@29.0',\n",
              " 38: 'A1@70.0',\n",
              " 39: 'A1@77.0',\n",
              " 40: 'A1@38.0',\n",
              " 41: 'A1@74.0',\n",
              " 42: 'A1@76.0',\n",
              " 43: 'A2@1.0',\n",
              " 44: 'A2@0.0',\n",
              " 45: 'A3@1.0',\n",
              " 46: 'A3@4.0',\n",
              " 47: 'A3@3.0',\n",
              " 48: 'A3@2.0',\n",
              " 49: 'A4@145.0',\n",
              " 50: 'A4@160.0',\n",
              " 51: 'A4@120.0',\n",
              " 52: 'A4@130.0',\n",
              " 53: 'A4@140.0',\n",
              " 54: 'A4@172.0',\n",
              " 55: 'A4@150.0',\n",
              " 56: 'A4@110.0',\n",
              " 57: 'A4@132.0',\n",
              " 58: 'A4@117.0',\n",
              " 59: 'A4@135.0',\n",
              " 60: 'A4@112.0',\n",
              " 61: 'A4@105.0',\n",
              " 62: 'A4@124.0',\n",
              " 63: 'A4@125.0',\n",
              " 64: 'A4@142.0',\n",
              " 65: 'A4@128.0',\n",
              " 66: 'A4@170.0',\n",
              " 67: 'A4@155.0',\n",
              " 68: 'A4@104.0',\n",
              " 69: 'A4@180.0',\n",
              " 70: 'A4@138.0',\n",
              " 71: 'A4@108.0',\n",
              " 72: 'A4@134.0',\n",
              " 73: 'A4@122.0',\n",
              " 74: 'A4@115.0',\n",
              " 75: 'A4@118.0',\n",
              " 76: 'A4@100.0',\n",
              " 77: 'A4@200.0',\n",
              " 78: 'A4@94.0',\n",
              " 79: 'A4@165.0',\n",
              " 80: 'A4@102.0',\n",
              " 81: 'A4@152.0',\n",
              " 82: 'A4@101.0',\n",
              " 83: 'A4@126.0',\n",
              " 84: 'A4@174.0',\n",
              " 85: 'A4@148.0',\n",
              " 86: 'A4@178.0',\n",
              " 87: 'A4@158.0',\n",
              " 88: 'A4@192.0',\n",
              " 89: 'A4@129.0',\n",
              " 90: 'A4@144.0',\n",
              " 91: 'A4@123.0',\n",
              " 92: 'A4@136.0',\n",
              " 93: 'A4@146.0',\n",
              " 94: 'A4@106.0',\n",
              " 95: 'A4@156.0',\n",
              " 96: 'A4@154.0',\n",
              " 97: 'A4@114.0',\n",
              " 98: 'A4@164.0',\n",
              " 99: 'A5@233.0',\n",
              " 100: 'A5@286.0',\n",
              " 101: 'A5@229.0',\n",
              " 102: 'A5@250.0',\n",
              " 103: 'A5@204.0',\n",
              " 104: 'A5@236.0',\n",
              " 105: 'A5@268.0',\n",
              " 106: 'A5@354.0',\n",
              " 107: 'A5@254.0',\n",
              " 108: 'A5@203.0',\n",
              " 109: 'A5@192.0',\n",
              " 110: 'A5@294.0',\n",
              " 111: 'A5@256.0',\n",
              " 112: 'A5@263.0',\n",
              " 113: 'A5@199.0',\n",
              " 114: 'A5@168.0',\n",
              " 115: 'A5@239.0',\n",
              " 116: 'A5@275.0',\n",
              " 117: 'A5@266.0',\n",
              " 118: 'A5@211.0',\n",
              " 119: 'A5@283.0',\n",
              " 120: 'A5@284.0',\n",
              " 121: 'A5@224.0',\n",
              " 122: 'A5@206.0',\n",
              " 123: 'A5@219.0',\n",
              " 124: 'A5@340.0',\n",
              " 125: 'A5@226.0',\n",
              " 126: 'A5@247.0',\n",
              " 127: 'A5@167.0',\n",
              " 128: 'A5@230.0',\n",
              " 129: 'A5@335.0',\n",
              " 130: 'A5@234.0',\n",
              " 131: 'A5@177.0',\n",
              " 132: 'A5@276.0',\n",
              " 133: 'A5@353.0',\n",
              " 134: 'A5@243.0',\n",
              " 135: 'A5@225.0',\n",
              " 136: 'A5@302.0',\n",
              " 137: 'A5@212.0',\n",
              " 138: 'A5@330.0',\n",
              " 139: 'A5@175.0',\n",
              " 140: 'A5@417.0',\n",
              " 141: 'A5@197.0',\n",
              " 142: 'A5@198.0',\n",
              " 143: 'A5@290.0',\n",
              " 144: 'A5@253.0',\n",
              " 145: 'A5@172.0',\n",
              " 146: 'A5@273.0',\n",
              " 147: 'A5@213.0',\n",
              " 148: 'A5@305.0',\n",
              " 149: 'A5@216.0',\n",
              " 150: 'A5@304.0',\n",
              " 151: 'A5@188.0',\n",
              " 152: 'A5@282.0',\n",
              " 153: 'A5@185.0',\n",
              " 154: 'A5@232.0',\n",
              " 155: 'A5@326.0',\n",
              " 156: 'A5@231.0',\n",
              " 157: 'A5@269.0',\n",
              " 158: 'A5@267.0',\n",
              " 159: 'A5@248.0',\n",
              " 160: 'A5@360.0',\n",
              " 161: 'A5@258.0',\n",
              " 162: 'A5@308.0',\n",
              " 163: 'A5@245.0',\n",
              " 164: 'A5@270.0',\n",
              " 165: 'A5@208.0',\n",
              " 166: 'A5@264.0',\n",
              " 167: 'A5@321.0',\n",
              " 168: 'A5@274.0',\n",
              " 169: 'A5@325.0',\n",
              " 170: 'A5@235.0',\n",
              " 171: 'A5@257.0',\n",
              " 172: 'A5@164.0',\n",
              " 173: 'A5@141.0',\n",
              " 174: 'A5@252.0',\n",
              " 175: 'A5@255.0',\n",
              " 176: 'A5@201.0',\n",
              " 177: 'A5@222.0',\n",
              " 178: 'A5@260.0',\n",
              " 179: 'A5@182.0',\n",
              " 180: 'A5@303.0',\n",
              " 181: 'A5@265.0',\n",
              " 182: 'A5@309.0',\n",
              " 183: 'A5@307.0',\n",
              " 184: 'A5@249.0',\n",
              " 185: 'A5@186.0',\n",
              " 186: 'A5@341.0',\n",
              " 187: 'A5@183.0',\n",
              " 188: 'A5@407.0',\n",
              " 189: 'A5@217.0',\n",
              " 190: 'A5@288.0',\n",
              " 191: 'A5@220.0',\n",
              " 192: 'A5@209.0',\n",
              " 193: 'A5@227.0',\n",
              " 194: 'A5@261.0',\n",
              " 195: 'A5@174.0',\n",
              " 196: 'A5@281.0',\n",
              " 197: 'A5@221.0',\n",
              " 198: 'A5@205.0',\n",
              " 199: 'A5@240.0',\n",
              " 200: 'A5@289.0',\n",
              " 201: 'A5@318.0',\n",
              " 202: 'A5@298.0',\n",
              " 203: 'A5@564.0',\n",
              " 204: 'A5@246.0',\n",
              " 205: 'A5@322.0',\n",
              " 206: 'A5@299.0',\n",
              " 207: 'A5@300.0',\n",
              " 208: 'A5@293.0',\n",
              " 209: 'A5@277.0',\n",
              " 210: 'A5@214.0',\n",
              " 211: 'A5@207.0',\n",
              " 212: 'A5@223.0',\n",
              " 213: 'A5@160.0',\n",
              " 214: 'A5@394.0',\n",
              " 215: 'A5@184.0',\n",
              " 216: 'A5@315.0',\n",
              " 217: 'A5@409.0',\n",
              " 218: 'A5@244.0',\n",
              " 219: 'A5@195.0',\n",
              " 220: 'A5@196.0',\n",
              " 221: 'A5@126.0',\n",
              " 222: 'A5@313.0',\n",
              " 223: 'A5@259.0',\n",
              " 224: 'A5@200.0',\n",
              " 225: 'A5@262.0',\n",
              " 226: 'A5@215.0',\n",
              " 227: 'A5@228.0',\n",
              " 228: 'A5@193.0',\n",
              " 229: 'A5@271.0',\n",
              " 230: 'A5@210.0',\n",
              " 231: 'A5@327.0',\n",
              " 232: 'A5@149.0',\n",
              " 233: 'A5@295.0',\n",
              " 234: 'A5@306.0',\n",
              " 235: 'A5@178.0',\n",
              " 236: 'A5@237.0',\n",
              " 237: 'A5@218.0',\n",
              " 238: 'A5@242.0',\n",
              " 239: 'A5@319.0',\n",
              " 240: 'A5@166.0',\n",
              " 241: 'A5@180.0',\n",
              " 242: 'A5@311.0',\n",
              " 243: 'A5@278.0',\n",
              " 244: 'A5@342.0',\n",
              " 245: 'A5@169.0',\n",
              " 246: 'A5@187.0',\n",
              " 247: 'A5@157.0',\n",
              " 248: 'A5@176.0',\n",
              " 249: 'A5@241.0',\n",
              " 250: 'A5@131.0',\n",
              " 251: 'A6@1.0',\n",
              " 252: 'A6@0.0',\n",
              " 253: 'A7@2.0',\n",
              " 254: 'A7@0.0',\n",
              " 255: 'A7@1.0',\n",
              " 256: 'A8@150.0',\n",
              " 257: 'A8@108.0',\n",
              " 258: 'A8@129.0',\n",
              " 259: 'A8@187.0',\n",
              " 260: 'A8@172.0',\n",
              " 261: 'A8@178.0',\n",
              " 262: 'A8@160.0',\n",
              " 263: 'A8@163.0',\n",
              " 264: 'A8@147.0',\n",
              " 265: 'A8@155.0',\n",
              " 266: 'A8@148.0',\n",
              " 267: 'A8@153.0',\n",
              " 268: 'A8@142.0',\n",
              " 269: 'A8@173.0',\n",
              " 270: 'A8@162.0',\n",
              " 271: 'A8@174.0',\n",
              " 272: 'A8@168.0',\n",
              " 273: 'A8@139.0',\n",
              " 274: 'A8@171.0',\n",
              " 275: 'A8@144.0',\n",
              " 276: 'A8@132.0',\n",
              " 277: 'A8@158.0',\n",
              " 278: 'A8@114.0',\n",
              " 279: 'A8@151.0',\n",
              " 280: 'A8@161.0',\n",
              " 281: 'A8@179.0',\n",
              " 282: 'A8@120.0',\n",
              " 283: 'A8@112.0',\n",
              " 284: 'A8@137.0',\n",
              " 285: 'A8@157.0',\n",
              " 286: 'A8@169.0',\n",
              " 287: 'A8@165.0',\n",
              " 288: 'A8@123.0',\n",
              " 289: 'A8@128.0',\n",
              " 290: 'A8@152.0',\n",
              " 291: 'A8@140.0',\n",
              " 292: 'A8@188.0',\n",
              " 293: 'A8@109.0',\n",
              " 294: 'A8@125.0',\n",
              " 295: 'A8@131.0',\n",
              " 296: 'A8@170.0',\n",
              " 297: 'A8@113.0',\n",
              " 298: 'A8@99.0',\n",
              " 299: 'A8@177.0',\n",
              " 300: 'A8@141.0',\n",
              " 301: 'A8@180.0',\n",
              " 302: 'A8@111.0',\n",
              " 303: 'A8@143.0',\n",
              " 304: 'A8@182.0',\n",
              " 305: 'A8@156.0',\n",
              " 306: 'A8@115.0',\n",
              " 307: 'A8@149.0',\n",
              " 308: 'A8@145.0',\n",
              " 309: 'A8@146.0',\n",
              " 310: 'A8@175.0',\n",
              " 311: 'A8@186.0',\n",
              " 312: 'A8@185.0',\n",
              " 313: 'A8@159.0',\n",
              " 314: 'A8@130.0',\n",
              " 315: 'A8@190.0',\n",
              " 316: 'A8@136.0',\n",
              " 317: 'A8@97.0',\n",
              " 318: 'A8@127.0',\n",
              " 319: 'A8@154.0',\n",
              " 320: 'A8@133.0',\n",
              " 321: 'A8@126.0',\n",
              " 322: 'A8@202.0',\n",
              " 323: 'A8@103.0',\n",
              " 324: 'A8@166.0',\n",
              " 325: 'A8@164.0',\n",
              " 326: 'A8@184.0',\n",
              " 327: 'A8@124.0',\n",
              " 328: 'A8@122.0',\n",
              " 329: 'A8@96.0',\n",
              " 330: 'A8@138.0',\n",
              " 331: 'A8@88.0',\n",
              " 332: 'A8@105.0',\n",
              " 333: 'A8@194.0',\n",
              " 334: 'A8@195.0',\n",
              " 335: 'A8@106.0',\n",
              " 336: 'A8@167.0',\n",
              " 337: 'A8@95.0',\n",
              " 338: 'A8@192.0',\n",
              " 339: 'A8@117.0',\n",
              " 340: 'A8@121.0',\n",
              " 341: 'A8@116.0',\n",
              " 342: 'A8@71.0',\n",
              " 343: 'A8@118.0',\n",
              " 344: 'A8@181.0',\n",
              " 345: 'A8@134.0',\n",
              " 346: 'A8@90.0',\n",
              " 347: 'A9@0.0',\n",
              " 348: 'A9@1.0',\n",
              " 349: 'A10@2.3',\n",
              " 350: 'A10@1.5',\n",
              " 351: 'A10@2.6',\n",
              " 352: 'A10@3.5',\n",
              " 353: 'A10@1.4',\n",
              " 354: 'A10@0.8',\n",
              " 355: 'A10@3.6',\n",
              " 356: 'A10@0.6',\n",
              " 357: 'A10@3.1',\n",
              " 358: 'A10@0.4',\n",
              " 359: 'A10@1.3',\n",
              " 360: 'A10@0.0',\n",
              " 361: 'A10@0.5',\n",
              " 362: 'A10@1.6',\n",
              " 363: 'A10@1.0',\n",
              " 364: 'A10@1.2',\n",
              " 365: 'A10@0.2',\n",
              " 366: 'A10@1.8',\n",
              " 367: 'A10@3.2',\n",
              " 368: 'A10@2.4',\n",
              " 369: 'A10@2.0',\n",
              " 370: 'A10@2.5',\n",
              " 371: 'A10@2.2',\n",
              " 372: 'A10@2.8',\n",
              " 373: 'A10@3.0',\n",
              " 374: 'A10@3.4',\n",
              " 375: 'A10@6.2',\n",
              " 376: 'A10@4.0',\n",
              " 377: 'A10@5.6',\n",
              " 378: 'A10@2.9',\n",
              " 379: 'A10@0.1',\n",
              " 380: 'A10@2.1',\n",
              " 381: 'A10@1.9',\n",
              " 382: 'A10@4.2',\n",
              " 383: 'A10@0.9',\n",
              " 384: 'A10@1.1',\n",
              " 385: 'A10@3.8',\n",
              " 386: 'A10@0.7',\n",
              " 387: 'A10@0.3',\n",
              " 388: 'A10@4.4',\n",
              " 389: 'A11@3.0',\n",
              " 390: 'A11@2.0',\n",
              " 391: 'A11@1.0',\n",
              " 392: 'A12@0.0',\n",
              " 393: 'A12@3.0',\n",
              " 394: 'A12@2.0',\n",
              " 395: 'A12@1.0',\n",
              " 396: 'A12@?',\n",
              " 397: 'A13@6.0',\n",
              " 398: 'A13@3.0',\n",
              " 399: 'A13@7.0',\n",
              " 400: 'A13@?'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv_dl9RS3s1F"
      },
      "source": [
        "mapping = {\n",
        "    \n",
        "   'A10':'oldpeak',\n",
        "           'A11':'slope',\t\n",
        "           'A12':'ca',\t\n",
        "           'A13':'thal',\n",
        "    'A1':'AGE',\n",
        "           'A2':'SEX', 'A3':'cp',\n",
        "           'A4':\t'trestbps'\t,\n",
        "           'A5': 'chol',\n",
        "           'A6':'fbs',\n",
        "           'A7':'restecg',\n",
        "           'A8':'thalach',\n",
        "           'A9':'exang'\n",
        "           \n",
        "           }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi2_-x6T4SoV"
      },
      "source": [
        "#min_support = np.arange(0.1, .11, 0.01)\n",
        "min_support = [0.1]\n",
        "d= \"/content/\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXluIZqe44dN"
      },
      "source": [
        "def parse_input(filename):\n",
        "                with open(filename) as f:\n",
        "                    data = [set(literal_eval(line)) for line in f]\n",
        "                return data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7u_vqchHI6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9000d877-e53c-4ff0-e58a-503061941400"
      },
      "source": [
        "import os\n",
        "from ast import literal_eval\n",
        "\n",
        "for i in (min_support):\n",
        "          print(round(i,2))\n",
        "          print(str(round(i,2)).replace('0.', ''))\n",
        "          file_to_process = d+\"outputclevdataFP\"+str(round(i,2)).replace('0.', '')+\".txt\"\n",
        "          superset_file = d+\"superset\"+str(round(i,2)).replace('0.', '')+\".txt\"\n",
        "          superset_file_final = d+\"superset\"+str(round(i,2)).replace('0.', '')+\"_final\"+\".txt\"\n",
        "          superset_file_final_v1 = d+\"superset\"+str(round(i,2)).replace('0.', '')+\"_final_v1\"+\".txt\"\n",
        "          rule_file = d+\"output_rules\"+str(round(i,2)).replace('0.', '')+\".txt\"\n",
        "          rule_file_final = d+\"output_rules_final_\"+str(round(i,2)).replace('0.', '')+\".txt\"\n",
        "          \n",
        "          f = open(file_to_process,'r')\n",
        "          lst = []\n",
        "          for line in f:\n",
        "              line  = line.split(\"SUP\", 1)\n",
        "        \n",
        "              line  = line[0]\n",
        "              lst.append(line)\n",
        "          f.close()\n",
        "          f = open(file_to_process,'w')\n",
        "          for line in lst:\n",
        "              f.write(line+'\\n')\n",
        "          f.close()\n",
        "\n",
        "          f = open(file_to_process,'r')\n",
        "          lst = []\n",
        "          for line in f:\n",
        "              line  = line.split(\"#\", 1)\n",
        "        \n",
        "              line  = line[0]\n",
        "              lst.append(line)\n",
        "          f.close()\n",
        "          f = open(file_to_process,'w')\n",
        "          for line in lst:\n",
        "              f.write(line+'\\n')\n",
        "          f.close()\n",
        "\n",
        "          rpp_process = pd.read_csv(file_to_process, header=None, names=[\"itemsets\"],index_col=False)\n",
        "\n",
        "          temp_df = pd.concat([rpp_process[['itemsets']], rpp_process['itemsets'].str.split(' ', expand=True)], axis=1)\n",
        "\n",
        "          temp_df=temp_df.drop('itemsets', axis=1)\n",
        "\n",
        "        #for class , moving the class column as first\n",
        "          with open(\"/content/temp_file.csv\", 'w') as f:\n",
        "                for row in temp_df.itertuples(index=False):\n",
        "                    #print(row)\n",
        "                    ls = list(row)\n",
        "                    ls = [x for x in ls if x]\n",
        "                    try:\n",
        "                      if '0' or '1' in ls:\n",
        "                            old_index = ls.index('0') if '0' in ls else ls.index('1')\n",
        "                            #print(\"old_index\", old_index)\n",
        "                            \n",
        "                            ls.insert(0, ls.pop(old_index))\n",
        "                            #print(\"after row\", ls)\n",
        "                            f.write(str(ls)+'\\n')\n",
        "                    except ValueError:\n",
        "                      pass\n",
        "\n",
        "          def compute_output(output_file, data, filter_value):\n",
        "              ls = data\n",
        "              index_to_pop=[]\n",
        "              for set1 in ls:\n",
        "                #print(\"set1\", set1)\n",
        "                for set2 in ls:\n",
        "                    if set1 is set2:\n",
        "                        # Do not try to compare a row with itself\n",
        "                        continue\n",
        "                    elif len(set(set1).difference(set(set2))) == 0:\n",
        "                          if set1 in ls:\n",
        "                            index = ls.index(set1)\n",
        "                            index_to_pop.append(index)\n",
        "\n",
        "                            break\n",
        "              print(\"Final index_to_pop\",index_to_pop)              \n",
        "              for index in sorted(index_to_pop, reverse=True):\n",
        "                  del ls[index]           \n",
        "              print(\"Final list\",ls)\n",
        "\n",
        "              f = open(superset_file,'w')\n",
        "              for line in ls:\n",
        "                f.write(str(line)+'\\n')\n",
        "              f.close()\n",
        "\n",
        "          def filter_file(path, filter_value=3, in_name='temp_file.csv', out_name='filteredSets'):\n",
        "              data = parse_input(os.path.join(path, in_name))\n",
        "              print(\"data\", data)\n",
        "              output_filename = os.path.join(path, '{}{}'.format(out_name, filter_value))\n",
        "              with open(output_filename, 'w') as out_file:\n",
        "                  compute_output(out_file, data, filter_value)\n",
        "\n",
        "          filter_file('/content')\n",
        "\n",
        "          print(\"longest ones sorted\")\n",
        "\n",
        "          with open(superset_file) as filein, open(superset_file_final,'w') as fileout:\n",
        "                    for line in filein:\n",
        "                            line=line.replace(\"'\",\"\")\n",
        "                            line=line.replace(\"}\",\"\")\n",
        "                            line=line.replace(\"{\",\"\")\n",
        "                            line=line.replace(\", \",\" \")\n",
        "                            fileout.write(line)\n",
        "\n",
        "            \n",
        "          with open(superset_file_final) as filein, open(superset_file_final_v1,'w') as fileout:\n",
        "              for line in filein:\n",
        "                  line=line.replace(\"[\",\"\")\n",
        "                  line=line.replace(\"]\",\"\")\n",
        "                  fileout.write(line)\n",
        "\n",
        "          rpp_process = pd.read_csv(superset_file_final_v1, header=None, names=[\"itemsets\"],index_col=False)\n",
        "\n",
        "          temp_df = pd.concat([rpp_process[['itemsets']], rpp_process['itemsets'].str.split(' ', expand=True)], axis=1)\n",
        "\n",
        "          temp_df=temp_df.drop('itemsets', axis=1)\n",
        "\n",
        "          with open(superset_file, 'w') as f:\n",
        "                  for row in temp_df.itertuples(index=False):\n",
        "                      ls = list(row)\n",
        "                      ls = [x for x in ls if x]\n",
        "                      try:\n",
        "                        if '0' or '1' in ls:\n",
        "                              old_index = ls.index('0') if '0' in ls else ls.index('1')\n",
        "                              #print(\"old_index\", old_index)\n",
        "                              \n",
        "                              ls.insert(0, ls.pop(old_index))\n",
        "                              #print(\"after row\", ls)\n",
        "                              f.write(str(ls)+'\\n')\n",
        "                      except ValueError:\n",
        "                        pass\n",
        "\n",
        "          with open(superset_file) as filein, open(superset_file_final,'w') as fileout:\n",
        "                    for line in filein:\n",
        "                            line=line.replace(\"'\",\"\")\n",
        "                            line=line.replace(\"}\",\"\")\n",
        "                            line=line.replace(\"{\",\"\")\n",
        "                            line=line.replace(\", \",\" \")\n",
        "                            fileout.write(line)\n",
        "\n",
        "            \n",
        "          with open(superset_file_final) as filein, open(superset_file_final_v1,'w') as fileout:\n",
        "              for line in filein:\n",
        "                  line=line.replace(\"[\",\"\")\n",
        "                  line=line.replace(\"]\",\"\")\n",
        "                  fileout.write(line)\n",
        "\n",
        "          superset = pd.read_csv(superset_file_final_v1,header=None, names=[\"itemsets\"],index_col=False)\n",
        "\n",
        "          superset_df = pd.concat([superset[['itemsets']], superset['itemsets'].str.split(' ', expand=True)], axis=1\n",
        "                  )\n",
        "            \n",
        "          superset_df.to_csv(\"superset_df.csv\", header=None, index=False)\n",
        "\n",
        "          print(\"Superset is done\")\n",
        "\n",
        "            \n",
        "            #superset_df = superset_df.loc[superset_df.iloc[:,1].isin(['1','0'])] #filtering rows\n",
        "\n",
        "          #superset_df = superset_df.loc[superset_df.iloc[:,1].isin(['1'])] #filtering only for minority\n",
        "\n",
        "          superset_df.to_csv(\"superset_df_1.csv\", header=None, index=False)\n",
        "\n",
        "          superset_df=superset_df.drop('itemsets', axis=1)\n",
        "\n",
        "          print(\"lenght of columns\", len(superset_df.columns))\n",
        "\n",
        "          if len(superset_df.columns) ==14:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e', 'f','g', 'h', 'i','j','k', 'l', 'm', 'n']\n",
        "          elif len(superset_df.columns) ==13:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e', 'f','g', 'h', 'i','j', 'k', 'l', 'm']\n",
        "          elif len(superset_df.columns) ==12:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e', 'f','g', 'h', 'i','j', 'k', 'l']\n",
        "          elif len(superset_df.columns) ==11:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e', 'f','g', 'h', 'i','j', 'k']\n",
        "          elif len(superset_df.columns) ==10:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e', 'f','g', 'h', 'i','j']\n",
        "          elif len(superset_df.columns) ==9:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e', 'f','g', 'h', 'i']\n",
        "          elif len(superset_df.columns) ==8:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e', 'f','g', 'h']\n",
        "\n",
        "          elif len(superset_df.columns) ==7:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e', 'f','g']\n",
        "\n",
        "          elif len(superset_df.columns) ==6:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e', 'f']\n",
        "\n",
        "          elif len(superset_df.columns) ==5:\n",
        "              superset_df.columns = ['a', 'b', 'c', 'd', 'e']\n",
        "\n",
        "          for i,n in enumerate(superset_df.columns):\n",
        "  \n",
        "                    superset_df[n] = '@' + superset_df[n].astype(str)\n",
        "\n",
        "          di = {f'@{k}': v for k, v in my_dict.items()}\n",
        "\n",
        "            \n",
        "          for col in superset_df:\n",
        "              superset_df[col] = superset_df[col].replace(di)\n",
        "\n",
        "          print(\"Mapping is done\")\n",
        "          superset_df.to_csv(\"superset_df_1_after_mapping.csv\", header=None, index=False) \n",
        "          \n",
        "          \n",
        "          if len(superset_df.columns) ==14:\n",
        "\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']+','+superset_df['f']+','+superset_df['g']+','+superset_df['h']+','+superset_df['i']+','+superset_df['j']+','+superset_df['k']+','+superset_df['l']+','+superset_df['m']+','+superset_df['n']\n",
        "\n",
        "          elif len(superset_df.columns) ==13:\n",
        "\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']+','+superset_df['f']+','+superset_df['g']+','+superset_df['h']+','+superset_df['i']+','+superset_df['j']+','+superset_df['k']+','+superset_df['l']+','+superset_df['m']\n",
        "\n",
        "          elif len(superset_df.columns) ==12:\n",
        "\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']+','+superset_df['f']+','+superset_df['g']+','+superset_df['h']+','+superset_df['i']+','+superset_df['j']+','+superset_df['k']+','+superset_df['l']\n",
        "          \n",
        "          elif len(superset_df.columns) ==11:\n",
        "\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']+','+superset_df['f']+','+superset_df['g']+','+superset_df['h']+','+superset_df['i']+','+superset_df['j']+','+superset_df['k']\n",
        "\n",
        "          \n",
        "          elif len(superset_df.columns) ==10:\n",
        "\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']+','+superset_df['f']+','+superset_df['g']+','+superset_df['h']+','+superset_df['i']+','+superset_df['j']\n",
        "          \n",
        "          \n",
        "          elif len(superset_df.columns) ==9:\n",
        "\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']+','+superset_df['f']+','+superset_df['g']+','+superset_df['h']+','+superset_df['i']\n",
        "          elif len(superset_df.columns) ==8:\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']+','+superset_df['f']+','+superset_df['g']+','+superset_df['h']\n",
        "          \n",
        "          elif len(superset_df.columns) ==7:\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']+','+superset_df['f']+','+superset_df['g']\n",
        "          \n",
        "          elif len(superset_df.columns) ==6:\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']+','+superset_df['f']\n",
        "          \n",
        "          elif len(superset_df.columns) ==5:\n",
        "              superset_df['rules'] = superset_df['b']+','+superset_df['c']+','+superset_df['d']+','+superset_df['e']\n",
        "          \n",
        "          \n",
        "          \n",
        "          \n",
        "          superset_df['pos'] = superset_df['rules'].str.find('@None')\n",
        "          superset_df['rules'] = superset_df.apply(lambda x: x['rules'][0:x['pos']],axis=1)\n",
        "          superset_df['rules'] = superset_df['rules']+\">\"+superset_df['a']\n",
        "          superset_df['rules'] = superset_df['rules'].str.replace(',@,','')\n",
        "          superset_df['rules'] = superset_df['rules'].str.replace(',>','>')\n",
        "\n",
        "          superset_df['rules'].to_csv(rule_file_final, header=None, index=False)\n",
        "          #for classifer file\n",
        "          superset_df['rules'].to_csv(rule_file, header=None, index=False)\n",
        "\n",
        "          print(\"Rules generated\")\n",
        "          text = rule_file_final\n",
        "          fields = mapping\n",
        "\n",
        "          lst = []\n",
        "          for line in fileinput.input(text):\n",
        "              for field in fields:\n",
        "                  if field in line:\n",
        "                      line = line.replace(field, fields[field])\n",
        "              lst.append(line)\n",
        "\n",
        "          print(lst)\n",
        "\n",
        "          f = open(rule_file_final,'w')\n",
        "          for line in lst:\n",
        "              f.write(line)\n",
        "          f.close()\n",
        "\n",
        "          print(\"Rules mapping done\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n",
            "1\n",
            "data [{'394', '1'}, {'395', '1'}, {'395', '390', '1'}, {'46', '395', '1'}, {'46', '43', '395', '1'}, {'46', '252', '395', '1'}, {'43', '395', '1'}, {'43', '395', '252', '1'}, {'252', '395', '1'}, {'348', '399', '1'}, {'348', '399', '390', '1'}, {'390', '1', '399', '348', '46'}, {'390', '1', '399', '252', '348'}, {'348', '399', '1', '46'}, {'43', '1', '399', '348', '46'}, {'43', '1', '399', '252', '348', '46'}, {'1', '399', '252', '348', '46'}, {'348', '399', '43', '1'}, {'43', '1', '399', '252', '348'}, {'348', '399', '252', '1'}, {'348', '1'}, {'348', '390', '1'}, {'348', '46', '390', '1'}, {'43', '390', '1', '348', '46'}, {'43', '390', '1', '252', '348', '46'}, {'390', '1', '252', '348', '46'}, {'348', '43', '390', '1'}, {'43', '390', '1', '252', '348'}, {'348', '252', '390', '1'}, {'348', '46', '1'}, {'348', '46', '253', '1'}, {'43', '1', '253', '348', '46'}, {'1', '252', '253', '348', '46'}, {'348', '46', '43', '1'}, {'43', '1', '252', '348', '46'}, {'348', '46', '252', '1'}, {'348', '253', '1'}, {'348', '43', '253', '1'}, {'348', '254', '1'}, {'348', '43', '1'}, {'348', '43', '252', '1'}, {'348', '252', '1'}, {'399', '1'}, {'399', '390', '1'}, {'399', '390', '1', '46'}, {'43', '390', '1', '399', '46'}, {'43', '390', '1', '399', '252', '46'}, {'390', '1', '399', '252', '46'}, {'399', '253', '390', '1'}, {'399', '43', '390', '1'}, {'43', '390', '1', '399', '252'}, {'399', '252', '390', '1'}, {'399', '1', '46'}, {'399', '253', '1', '46'}, {'43', '1', '399', '253', '46'}, {'1', '399', '252', '253', '46'}, {'399', '43', '1', '46'}, {'43', '1', '399', '252', '46'}, {'399', '252', '1', '46'}, {'399', '253', '1'}, {'399', '43', '253', '1'}, {'43', '1', '399', '252', '253'}, {'399', '252', '253', '1'}, {'399', '254', '1'}, {'43', '399', '254', '1'}, {'254', '43', '1', '399', '252'}, {'399', '254', '252', '1'}, {'347', '399', '1'}, {'347', '399', '43', '1'}, {'347', '399', '252', '1'}, {'399', '43', '1'}, {'399', '43', '252', '1'}, {'399', '252', '1'}, {'1'}, {'390', '1'}, {'46', '390', '1'}, {'46', '253', '390', '1'}, {'43', '390', '1', '253', '46'}, {'390', '1', '252', '253', '46'}, {'46', '43', '390', '1'}, {'43', '390', '1', '252', '46'}, {'46', '252', '390', '1'}, {'253', '390', '1'}, {'253', '43', '390', '1'}, {'43', '390', '1', '252', '253'}, {'253', '252', '390', '1'}, {'254', '390', '1'}, {'254', '252', '390', '1'}, {'347', '390', '1'}, {'43', '390', '1'}, {'43', '252', '390', '1'}, {'252', '390', '1'}, {'391', '1'}, {'43', '391', '1'}, {'252', '391', '1'}, {'46', '1'}, {'46', '253', '1'}, {'46', '43', '253', '1'}, {'43', '1', '252', '253', '46'}, {'46', '252', '253', '1'}, {'46', '254', '1'}, {'43', '46', '254', '1'}, {'46', '254', '252', '1'}, {'46', '1', '392'}, {'347', '46', '1'}, {'46', '43', '1'}, {'46', '43', '252', '1'}, {'46', '252', '1'}, {'253', '1'}, {'347', '253', '1'}, {'347', '252', '253', '1'}, {'43', '253', '1'}, {'43', '252', '253', '1'}, {'252', '253', '1'}, {'254', '1'}, {'254', '43', '1'}, {'254', '43', '252', '1'}, {'254', '252', '1'}, {'398', '1'}, {'252', '398', '1'}, {'1', '392'}, {'43', '1', '392'}, {'43', '252', '1', '392'}, {'252', '1', '392'}, {'347', '1'}, {'347', '43', '1'}, {'347', '43', '252', '1'}, {'347', '252', '1'}, {'43', '1'}, {'43', '252', '1'}, {'252', '1'}]\n",
            "Final index_to_pop [1, 3, 6, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 85, 86, 89, 90, 91, 92, 95, 96, 97, 99, 100, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 124, 125, 127, 128, 129, 130]\n",
            "Final list [{'394', '1'}, {'395', '390', '1'}, {'46', '43', '395', '1'}, {'46', '252', '395', '1'}, {'43', '395', '252', '1'}, {'390', '1', '399', '348', '46'}, {'390', '1', '399', '252', '348'}, {'43', '1', '399', '252', '348', '46'}, {'43', '390', '1', '252', '348', '46'}, {'43', '1', '253', '348', '46'}, {'1', '252', '253', '348', '46'}, {'348', '254', '1'}, {'43', '390', '1', '399', '252', '46'}, {'399', '253', '390', '1'}, {'43', '1', '399', '253', '46'}, {'1', '399', '252', '253', '46'}, {'43', '1', '399', '252', '253'}, {'254', '43', '1', '399', '252'}, {'347', '399', '43', '1'}, {'347', '399', '252', '1'}, {'43', '390', '1', '253', '46'}, {'390', '1', '252', '253', '46'}, {'43', '390', '1', '252', '253'}, {'254', '252', '390', '1'}, {'347', '390', '1'}, {'43', '391', '1'}, {'252', '391', '1'}, {'43', '1', '252', '253', '46'}, {'43', '46', '254', '1'}, {'46', '254', '252', '1'}, {'46', '1', '392'}, {'347', '46', '1'}, {'347', '252', '253', '1'}, {'252', '398', '1'}, {'43', '252', '1', '392'}, {'347', '43', '252', '1'}]\n",
            "longest ones sorted\n",
            "Superset is done\n",
            "lenght of columns 6\n",
            "Mapping is done\n",
            "Rules generated\n",
            "['ca@2.0>class@1\\n', '\"ca@1.0,slope@2.0>class@1\"\\n', '\"cp@4.0,SEX@1.0,ca@1.0>class@1\"\\n', '\"cp@4.0,fbs@0.0,ca@1.0>class@1\"\\n', '\"SEX@1.0,ca@1.0,fbs@0.0>class@1\"\\n', '\"slope@2.0,thal@7.0,exang@1.0,cp@4.0>class@1\"\\n', '\"slope@2.0,thal@7.0,fbs@0.0,exang@1.0>class@1\"\\n', '\"SEX@1.0,thal@7.0,fbs@0.0,exang@1.0,cp@4.>class@1\"\\n', '\"SEX@1.0,slope@2.0,fbs@0.0,exang@1.0,cp@4.>class@1\"\\n', '\"SEX@1.0,restecg@2.0,exang@1.0,cp@4.0>class@1\"\\n', '\"fbs@0.0,restecg@2.0,exang@1.0,cp@4.0>class@1\"\\n', '\"exang@1.0,restecg@0.0>class@1\"\\n', '\"SEX@1.0,slope@2.0,thal@7.0,fbs@0.0,cp@4.>class@1\"\\n', '\"thal@7.0,restecg@2.0,slope@2.0>class@1\"\\n', '\"SEX@1.0,thal@7.0,restecg@2.0,cp@4.0>class@1\"\\n', '\"thal@7.0,fbs@0.0,restecg@2.0,cp@4.0>class@1\"\\n', '\"SEX@1.0,thal@7.0,fbs@0.0,restecg@2.0>class@1\"\\n', '\"restecg@0.0,SEX@1.0,thal@7.0,fbs@0.0>class@1\"\\n', '\"exang@0.0,thal@7.0,SEX@1.0>class@1\"\\n', '\"exang@0.0,thal@7.0,fbs@0.0>class@1\"\\n', '\"SEX@1.0,slope@2.0,restecg@2.0,cp@4.0>class@1\"\\n', '\"slope@2.0,fbs@0.0,restecg@2.0,cp@4.0>class@1\"\\n', '\"SEX@1.0,slope@2.0,fbs@0.0,restecg@2.0>class@1\"\\n', '\"restecg@0.0,fbs@0.0,slope@2.0>class@1\"\\n', '\"exang@0.0,slope@2.0>class@1\"\\n', '\"SEX@1.0,slope@1.0>class@1\"\\n', '\"fbs@0.0,slope@1.0>class@1\"\\n', '\"SEX@1.0,fbs@0.0,restecg@2.0,cp@4.0>class@1\"\\n', '\"SEX@1.0,cp@4.0,restecg@0.0>class@1\"\\n', '\"cp@4.0,restecg@0.0,fbs@0.0>class@1\"\\n', '\"cp@4.0,ca@0.0>class@1\"\\n', '\"exang@0.0,cp@4.0>class@1\"\\n', '\"exang@0.0,fbs@0.0,restecg@2.0>class@1\"\\n', '\"fbs@0.0,thal@3.0>class@1\"\\n', '\"SEX@1.0,fbs@0.0,ca@0.0>class@1\"\\n', '\"exang@0.0,SEX@1.0,fbs@0.0>class@1\"\\n']\n",
            "Rules mapping done\n"
          ]
        }
      ]
    }
  ]
}